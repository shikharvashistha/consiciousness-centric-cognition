"""
Cognitive cycle schemas and data models

Represents the 7-step cognitive cycle that forms the core of AGI processing
"""

import uuid
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Any, Optional, List
from enum import Enum

class CognitiveCycleStep(Enum):
    """Steps in the cognitive cycle"""
    PERCEIVE = "perceive"           # Neural substrate processes input
    ORIENT = "orient"               # Consciousness core calculates state
    DECIDE = "decide"               # Recall + Creative collaboration
    ETHICAL_REVIEW = "ethical"      # Ethical governor validation
    ACT = "act"                     # Parallel mind execution
    REFLECT = "reflect"             # Code introspection analysis
    LEARN = "learn"                 # Perfect recall storage

class CognitiveCycleStatus(Enum):
    """Status of cognitive cycle execution"""
    INITIALIZING = "initializing"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    ABORTED = "aborted"

@dataclass
class StepResult:
    """Result of a single cognitive cycle step"""
    step: CognitiveCycleStep
    start_time: datetime
    end_time: Optional[datetime] = None
    duration_ms: Optional[float] = None
    success: bool = False
    result_data: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    metrics: Optional[Dict[str, float]] = None
    
    def __post_init__(self):
        """Calculate duration if end_time is set"""
        if self.end_time and self.start_time:
            delta = self.end_time - self.start_time
            self.duration_ms = delta.total_seconds() * 1000

@dataclass
class CreativeIdea:
    """Represents a creative idea generated by the creative engine"""
    idea_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    title: str = ""
    description: str = ""
    approach: str = ""
    expected_outcome: str = ""
    confidence_score: float = 0.0
    novelty_score: float = 0.0
    feasibility_score: float = 0.0
    risk_assessment: Dict[str, float] = field(default_factory=dict)
    implementation_steps: List[str] = field(default_factory=list)
    required_resources: List[str] = field(default_factory=list)
    estimated_time: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        """Validate creative idea data"""
        for score in [self.confidence_score, self.novelty_score, self.feasibility_score]:
            if not 0.0 <= score <= 1.0:
                raise ValueError("Scores must be between 0.0 and 1.0")

@dataclass
class EthicalEvaluation:
    """Result of ethical evaluation"""
    approved: bool = False
    confidence: float = 0.0
    risk_level: str = "unknown"  # low, medium, high, critical
    ethical_frameworks_used: List[str] = field(default_factory=list)
    concerns: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    bias_detected: bool = False
    safety_score: float = 0.0
    alignment_score: float = 0.0
    explanation: str = ""
    
    def __post_init__(self):
        """Validate ethical evaluation"""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError("Confidence must be between 0.0 and 1.0")
        if not 0.0 <= self.safety_score <= 1.0:
            raise ValueError("Safety score must be between 0.0 and 1.0")
        if not 0.0 <= self.alignment_score <= 1.0:
            raise ValueError("Alignment score must be between 0.0 and 1.0")

@dataclass
class ExecutionResult:
    """Result of parallel execution"""
    success: bool = False
    output: Optional[Any] = None
    subtasks_completed: int = 0
    total_subtasks: int = 0
    execution_time_ms: float = 0.0
    resource_usage: Dict[str, float] = field(default_factory=dict)
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)

@dataclass
class IntrospectionReport:
    """Result of code introspection analysis"""
    performance_score: float = 0.0
    code_quality_score: float = 0.0
    efficiency_score: float = 0.0
    maintainability_score: float = 0.0
    identified_issues: List[str] = field(default_factory=list)
    improvement_suggestions: List[str] = field(default_factory=list)
    optimization_opportunities: List[str] = field(default_factory=list)
    potential_bugs: List[str] = field(default_factory=list)
    complexity_analysis: Dict[str, float] = field(default_factory=dict)
    
    def __post_init__(self):
        """Validate introspection scores"""
        scores = [self.performance_score, self.code_quality_score, 
                 self.efficiency_score, self.maintainability_score]
        for score in scores:
            if not 0.0 <= score <= 1.0:
                raise ValueError("All scores must be between 0.0 and 1.0")

@dataclass
class CognitiveCycleState:
    """Complete state of a cognitive cycle execution"""
    # Identifiers
    cycle_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    parent_cycle_id: Optional[str] = None
    
    # Timing
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    total_duration_ms: Optional[float] = None
    
    # Input and context
    goal: Optional[str] = None
    user_context: Optional[Dict[str, Any]] = None
    input_data: Optional[Dict[str, Any]] = None
    
    # Step results
    step_results: Dict[CognitiveCycleStep, StepResult] = field(default_factory=dict)
    
    # Core data from each step
    neural_state: Optional[Dict[str, Any]] = None
    consciousness_state: Optional[Dict[str, Any]] = None
    retrieved_memories: Optional[List[Dict[str, Any]]] = None
    creative_idea: Optional[CreativeIdea] = None
    ethical_evaluation: Optional[EthicalEvaluation] = None
    execution_result: Optional[ExecutionResult] = None
    personalized_output: Optional[Dict[str, Any]] = None
    introspection_report: Optional[IntrospectionReport] = None
    
    # Final output
    final_output: Optional[Dict[str, Any]] = None
    
    # Status and metadata
    status: CognitiveCycleStatus = CognitiveCycleStatus.INITIALIZING
    error: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    
    # Performance metrics
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    resource_usage: Dict[str, float] = field(default_factory=dict)
    
    def __post_init__(self):
        """Calculate total duration if end_time is set"""
        if self.end_time and self.start_time:
            delta = self.end_time - self.start_time
            self.total_duration_ms = delta.total_seconds() * 1000
    
    @property
    def is_complete(self) -> bool:
        """Check if cycle is complete"""
        return self.status == CognitiveCycleStatus.COMPLETED
    
    @property
    def is_successful(self) -> bool:
        """Check if cycle completed successfully"""
        return self.is_complete and self.error is None
    
    @property
    def completion_percentage(self) -> float:
        """Calculate completion percentage based on completed steps"""
        total_steps = len(CognitiveCycleStep)
        completed_steps = len([r for r in self.step_results.values() if r.success])
        return (completed_steps / total_steps) * 100
    
    def add_step_result(self, step_result: StepResult):
        """Add result for a cognitive cycle step"""
        self.step_results[step_result.step] = step_result
        
        # Update performance metrics
        if step_result.duration_ms:
            self.performance_metrics[f"{step_result.step.value}_duration_ms"] = step_result.duration_ms
        
        if step_result.metrics:
            for key, value in step_result.metrics.items():
                self.performance_metrics[f"{step_result.step.value}_{key}"] = value
    
    def get_step_result(self, step: CognitiveCycleStep) -> Optional[StepResult]:
        """Get result for a specific step"""
        return self.step_results.get(step)
    
    def mark_completed(self, final_output: Optional[Dict[str, Any]] = None):
        """Mark cycle as completed"""
        self.status = CognitiveCycleStatus.COMPLETED
        self.end_time = datetime.now()
        if final_output:
            self.final_output = final_output
        
        # Calculate total duration
        if self.start_time:
            delta = self.end_time - self.start_time
            self.total_duration_ms = delta.total_seconds() * 1000
    
    def mark_failed(self, error_message: str):
        """Mark cycle as failed"""
        self.status = CognitiveCycleStatus.FAILED
        self.error = error_message
        self.end_time = datetime.now()
        
        if self.start_time:
            delta = self.end_time - self.start_time
            self.total_duration_ms = delta.total_seconds() * 1000
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        return {
            'cycle_id': self.cycle_id,
            'parent_cycle_id': self.parent_cycle_id,
            'start_time': self.start_time.isoformat(),
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'total_duration_ms': self.total_duration_ms,
            'goal': self.goal,
            'status': self.status.value,
            'completion_percentage': self.completion_percentage,
            'is_successful': self.is_successful,
            'error': self.error,
            'warnings': self.warnings,
            'performance_metrics': self.performance_metrics,
            'resource_usage': self.resource_usage,
            'step_results': {
                step.value: {
                    'success': result.success,
                    'duration_ms': result.duration_ms,
                    'error_message': result.error_message
                } for step, result in self.step_results.items()
            }
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get performance summary of the cycle"""
        successful_steps = sum(1 for r in self.step_results.values() if r.success)
        total_steps = len(self.step_results)
        
        avg_step_duration = 0.0
        if self.step_results:
            durations = [r.duration_ms for r in self.step_results.values() if r.duration_ms]
            avg_step_duration = sum(durations) / len(durations) if durations else 0.0
        
        return {
            'cycle_id': self.cycle_id,
            'total_duration_ms': self.total_duration_ms or 0.0,
            'successful_steps': successful_steps,
            'total_steps': total_steps,
            'success_rate': (successful_steps / total_steps * 100) if total_steps > 0 else 0.0,
            'avg_step_duration_ms': avg_step_duration,
            'status': self.status.value,
            'has_errors': self.error is not None,
            'warning_count': len(self.warnings)
        }